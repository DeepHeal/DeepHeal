Metadata-Version: 2.4
Name: deepheal
Version: 1.0.12
Summary: DeepHeal: Self-supervised representations of drug-response proteomics
Home-page: https://github.com/DeepHeal/DeepHeal
Author: Disheng Feng
Author-email: fengds@fjtcm.edu.cn
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE.md
Requires-Dist: numpy
Requires-Dist: tqdm
Requires-Dist: pandas
Requires-Dist: scikit-learn
Requires-Dist: scipy
Requires-Dist: torch
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# DeepHeal: Self-supervised representations of drug-response proteomics

**DeepHeal** learns low-dimensional, denoised representations of **drug-induced proteomic changes** and exports them as CSV files for downstream machine learning models (e.g., **GLMVQ**, **LightGBM**).

Unlike typical single-cell workflows focusing on batch correction, DeepHeal is applied here to:

- **Input**: Bulk or aggregated proteomics **log2 fold-change (log2FC)** data (drug-treated vs. control).
- **Task**: **Unsupervised dimensionality reduction** (without batch effect modeling).
- **Output**: Low-dimensional embeddings (CSV) for each drug condition.
- **Labels (external)**: Drug efficacy classes (`Drug_Class`) from a meta file, used **only** for downstream classification, not for DeepHeal training.

Internally, DeepHeal implements a minimalist neural network with a single hidden layer and **contrastive learning** to obtain biologically meaningful latent features from proteomic responses.

---

## 1. Data Format

### 1.1 Proteomics log2FC matrix

- **File**: e.g., `proteomics_log2fc.csv`
- **Format**: CSV
- **Structure**:
    - Each **row** = one sample / drug condition
    - Each **column** = one protein
    - Each cell = **log2FC** (treated vs. control)

**Example:**

```csv
Sample_ID,PROT1,PROT2,PROT3,...
DrugA,0.52,-0.13,1.07,...
DrugB,-0.95,0.20,-0.33,...
...
```

**Requirements:**

- Values must be **log2-transformed fold-changes**.
- `Sample_ID` must uniquely identify each sample (e.g., drug name or treatment ID).

### 1.2 Meta file: drug classes

- **File**: e.g., `meta.csv`
- **Format**: CSV
- **Required columns**:
  - `Sample_ID`: Aligns with `Sample_ID` in the log2FC matrix.
  - `Drug_Class`: Pharmacological / efficacy class label.

**Example:**

代码段

```
Sample_ID,Drug_Class
DrugA,Kinase_inhibitor
DrugB,GPCR_antagonist
DrugC,Proteasome_inhibitor
...
```

**Notes:**

- `Drug_Class` is **not** used during DeepHeal training (self-supervised).
- It is only used later to train classifiers such as GLMVQ and LightGBM.

> **中文说明 (Chinese Note):**
>
> - **数据文件**: `proteomics_log2fc.csv`，行为样本（药物处理），列为蛋白，数值为相对于对照的 log2FC。
> - **元数据**: `meta.csv`，必须包含 `Sample_ID` (用于对齐) 和 `Drug_Class` (药效类别，用于后续分类)。

------

## 2. Installation

Clone this repository:

Bash

```
git clone [https://github.com/DeepHeal/DeepHeal.git](https://github.com/DeepHeal/DeepHeal.git)
cd DeepHeal
```

Install dependencies (adjust to your environment):

Bash

```
pip install -r requirements.txt
```

*DeepHeal is implemented in Python (PyTorch or equivalent deep learning framework; see `requirements.txt` for details).*

------

## 3. Usage

### 3.1 Prepare data

Place your input files in a data directory, for example:

Plaintext

```
data/
  proteomics_log2fc.csv   # log2FC matrix
  meta.csv                # Sample_ID + Drug_Class
```

**Make sure:**

- `proteomics_log2fc.csv` contains a `Sample_ID` column.
- `meta.csv` has matching `Sample_ID` values.

### 3.2 Train DeepHeal and generate embeddings

Run the main training script (e.g., `train_deepheal.py`) to generate the embeddings.

Bash

```
python trainer.py \
  --input data/proteomics_log2fc.csv \
  --id-col Sample_ID \
  --latent-dim 32 \
  --output embeddings/deepheal_latent_32d.csv \
  --no-batch
```

**Arguments:**

- `--input`: Path to the log2FC matrix CSV.
- `--id-col`: Name of the sample ID column (e.g., `Sample_ID`).
- `--latent-dim`: Dimensionality of the latent space (e.g., 16, 32, 64).
- `--output`: Output path for the embedding CSV.
- `--no-batch` (or equivalent flag): Disables batch-integration logic; DeepHeal is used purely for **dimensionality reduction** on a single integrated dataset.

### 3.3 Output format

DeepHeal produces a CSV file containing the low-dimensional embeddings.

**File:** `embeddings/deepheal_latent_32d.csv`

**Example Content:**

代码段

```
Sample_ID,z1,z2,z3,...,z32
DrugA,0.12,-0.08,0.33,...,1.05
DrugB,-0.27,0.44,-0.10,...,-0.92
...
```

The columns `z1, z2, ..., zK` are the learned feature representations per sample.

------

## 4. Downstream Classification (GLMVQ / LightGBM)

DeepHeal itself does **not** train supervised classifiers. You must export the embeddings and build your own models.

Below is a minimal Python example using **LightGBM**:

Python

```
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# 1. Load embeddings and meta data
Z = pd.read_csv("embeddings/deepheal_latent_32d.csv")
meta = pd.read_csv("data/meta.csv")

# 2. Merge on Sample_ID
df = Z.merge(meta, on="Sample_ID")

# 3. Define Features (z1...zN) and Labels (Drug_Class)
feature_cols = [c for c in df.columns if c.startswith("z")]
X = df[feature_cols]
y = df["Drug_Class"]

# Note: You may need to encode 'y' to integers if not already done.
# y = y.astype('category').cat.codes

# 4. Split Data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 5. Train LightGBM
train_data = lgb.Dataset(X_train, label=y_train)
valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)

params = {
    "objective": "multiclass",
    "num_class": y.nunique(),  # Ensure this matches your class count
    "metric": "multi_logloss",
    "learning_rate": 0.05,
    "num_leaves": 31,
    "verbose": -1
}

model = lgb.train(
    params,
    train_data,
    valid_sets=[valid_data],
    num_boost_round=200,
    callbacks=[lgb.early_stopping(stopping_rounds=20)]
)

# 6. Evaluate
y_pred = model.predict(X_test)
y_pred_labels = y_pred.argmax(axis=1)
print(classification_report(y_test, y_pred_labels))
```

*For **GLMVQ**, follow the API of your chosen implementation (e.g., `sklearn-lvq`) and feed `X` as features and `y` as labels.*

------

## 5. Method Summary

**DeepHeal Framework:**

- Uses a **single-hidden-layer** neural network.
- Trained via **self-supervised contrastive learning**.
- Learns latent representations that:
  - Denoise proteomic response profiles.
  - Preserve local and global data structure.
  - Capture biologically meaningful patterns (e.g., co-regulated proteins/pathways).

**In this repository:**

- We **do not** model or correct batch effects.
- We focus on using DeepHeal as a **general-purpose dimensionality reduction** tool for drug-response proteomics, preparing robust features for downstream machine learning.

------

## 6. License

MIT License
